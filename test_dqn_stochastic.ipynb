{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from rl.agent import DQNAgent\n",
    "from gymjsp.jsspenv import HeuristicJsspEnv\n",
    "from tianshou_ppo import tianshou_ppo_train\n",
    "from ortools_scheduler import ORtools_scheduler\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = [\"ft06\", \"orb01\", \"swv01\", \"swv06\", \"swv11\", \"yn1\", \n",
    "            \"swv12\", \"swv13\", \"swv14\", \"swv15\"]\n",
    "\n",
    "num_episodes = 100\n",
    "memory_size = 100000\n",
    "batch_size = 64\n",
    "target_update = 100\n",
    "noisy = False\n",
    "plotting_inteval = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 随机环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_rate = 0.5\n",
    "cv = 0.2\n",
    "epochs = 10\n",
    "n = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "directory = f\"figs_no_future_infomation/p{random_rate}cv{cv}epochs{epochs}_dqn\"\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "ret = {}\n",
    "\n",
    "ortools_mean, ortools_std, policy_mean, policy_std = [], [], [], []\n",
    "ortools_on_original, policy_on_original = [], []\n",
    "optimal_mean, optimal_std = [], []\n",
    "ortools_300s_optimal_rate = []\n",
    "current_instances = []\n",
    "\n",
    "for instance in instances:\n",
    "    sols_directory = f\"sols/{instance}/p{random_rate}cv{cv}\"\n",
    "    policy_file = f\"policies/dqn_mlp/{instance}_num_episodes={num_episodes}_memory_size={memory_size}_target_update={target_update}_noisy={noisy}.png\"\n",
    "    env = HeuristicJsspEnv(instance)\n",
    "    agent = DQNAgent(env, memory_size, batch_size, target_update, noisy=noisy)\n",
    "    agent.load_dqn(policy_file)\n",
    "    makespan = agent.test()\n",
    "    model = agent._get_dqn()\n",
    "\n",
    "    #makespan, policy = tianshou_ppo_train(instance_name=instance, max_epoch=epochs)\n",
    "    ret[instance] = makespan\n",
    "\n",
    "    scheduler = ORtools_scheduler(instance)\n",
    "    #scheduler.optimize()\n",
    "    #obj_val = scheduler.obj_val\n",
    "    scheduler.read_solution()           # 读取静态解\n",
    "    obj_val = scheduler.compute_makespan()\n",
    "\n",
    "    policy_vals, ortools_vals, optimal_vals, if_optimals = [], [], [], []\n",
    "\n",
    "    for i in range(n):\n",
    "        #times = scheduler.shifted_time_(random_rate=random_rate, cv=cv)\n",
    "        #policy_val = scheduler.policy_makespan('ppo', policy, shifted_time=times)\n",
    "\n",
    "        scheduler.load_time_mat(os.path.join(sols_directory, f\"{i}.npy\"))\n",
    "        times = scheduler.times\n",
    "        \n",
    "        policy_val = scheduler.policy_makespan('dqn', model, shifted_time=times)\n",
    "        ortools_val = scheduler.compute_makespan(shifted_time=times)        # 静态调度面对工时波动\n",
    "\n",
    "        #if_optimal, optimal_val = scheduler.get_optimal_of_new_time_mat(times)\n",
    "\n",
    "        policy_vals.append(policy_val)\n",
    "        ortools_vals.append(ortools_val)\n",
    "        #optimal_vals.append(optimal_val)\n",
    "        #if_optimals.append(int(if_optimal))\n",
    "\n",
    "    info_df = pd.read_csv(os.path.join(sols_directory, \"info.csv\")) ##############################\n",
    "    optimal_vals, if_optimals = info_df['obj_val'].values.tolist(), info_df['optimal'].values.tolist()\n",
    "\n",
    "    plt.plot(policy_vals, color='g', label='policy')\n",
    "    plt.plot(ortools_vals, color='r', label='ortools_static')\n",
    "    plt.plot(optimal_vals, color='blue', label='ortools_300s')\n",
    "    policy_vals, ortools_vals, optimal_vals = np.array(policy_vals), np.array(ortools_vals), np.array(optimal_vals)\n",
    "\n",
    "    plt.hlines(np.mean(ortools_vals), -2, n+2, linestyles='dotted', colors='r')\n",
    "    plt.hlines(np.mean(policy_vals), -2, n+2, linestyles='dotted', colors='g')\n",
    "    plt.hlines(np.mean(optimal_vals), -2, n+2, linestyles='dotted', colors='blue')\n",
    "    scatter_x = np.where(if_optimals)\n",
    "    scatter_y = np.array(optimal_vals)[scatter_x]\n",
    "    plt.scatter(scatter_x, scatter_y, color='blue')\n",
    "\n",
    "\n",
    "\n",
    "    ortools_mean.append(np.mean(ortools_vals))\n",
    "    ortools_std.append(np.std(ortools_vals))\n",
    "    policy_mean.append(np.mean(policy_vals))\n",
    "    policy_std.append(np.std(policy_vals))\n",
    "    optimal_mean.append(np.mean(optimal_vals))\n",
    "    optimal_std.append(np.std(optimal_vals))\n",
    "    ortools_on_original.append(obj_val)\n",
    "    policy_on_original.append(makespan)\n",
    "    ortools_300s_optimal_rate.append(np.mean(if_optimals))\n",
    "    current_instances.append(instance)\n",
    "\n",
    "    plt.xlabel('trial')\n",
    "    plt.ylabel('makespan')\n",
    "    plt.title(f\"random_rate={random_rate},cv={cv},instance={instance}\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{directory}/policy_vs_ortools_{instance}.png\")\n",
    "    plt.clf()\n",
    "\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "# 将每个列添加到 DataFrame 中\n",
    "df['instance'] = current_instances\n",
    "df['ortools_mean'] = ortools_mean\n",
    "df['policy_mean'] = policy_mean\n",
    "df['optimal_mean'] = optimal_mean\n",
    "df['ortools_std'] = ortools_std\n",
    "df['policy_std'] = policy_std\n",
    "df['optimal_std'] = optimal_std\n",
    "df['ortools_on_original'] = ortools_on_original\n",
    "df['policy_on_original'] = policy_on_original\n",
    "df['ortools_300s_optimal_rate'] = ortools_300s_optimal_rate\n",
    "\n",
    "if os.path.exists(f\"{directory}/data.csv\"):\n",
    "    df2 = pd.read_csv(f\"{directory}/data.csv\")\n",
    "    df2 = df2.append(df, ignore_index=True)\n",
    "    df2.to_csv(f\"{directory}/data.csv\", index=False)\n",
    "else:\n",
    "    df.to_csv(f\"{directory}/data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ft06': 60,\n",
       " 'orb01': 1355,\n",
       " 'swv01': 1701,\n",
       " 'swv06': 2154,\n",
       " 'swv11': 3504,\n",
       " 'yn1': 1185,\n",
       " 'swv12': 3731,\n",
       " 'swv13': 3813,\n",
       " 'swv14': 3610,\n",
       " 'swv15': 3256}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dce9ce0b8994960befdaf1abc06919148bccb19973be1d090d69590bd56698c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
