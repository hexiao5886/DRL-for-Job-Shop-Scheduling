{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rl_utils\n",
    "from GIN_jsspenv import GIN_JsspEnv\n",
    "from agent import PPO\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_lr = 2e-5\n",
    "critic_lr = 2e-5\n",
    "gamma = 0.98\n",
    "lmbda = 0.95\n",
    "epochs = 10\n",
    "eps = 0.2\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "agent = PPO(device, actor_lr, critic_lr, lmbda, epochs, eps, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 10                 # each iteraation contains len(sizes) independent instances, which including num_episodes_per_iter episodes\n",
    "num_episodes_per_iter = 5\n",
    "sizes = [(6,6),(10,10),(15,15),(20,20),(30,20)]\n",
    "instances = []\n",
    "for size in sizes:\n",
    "    num_jobs, num_machines = size\n",
    "    generated_instances_file = f\"DataGen/generatedData{num_jobs}_{num_machines}_Seed200.npy\"\n",
    "    generated_instances = np.load(generated_instances_file)\n",
    "    instances.append(generated_instances)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 iters done.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 6 but got size 10 for tensor number 36 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m return_lists \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m      2\u001b[0m makespan_lists \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mrl_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_policy_agent_parallel_envs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstances\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mnum_episodes_per_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_episodes_per_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_lists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_lists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmakespan_lists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmakespan_lists\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/DRL-for-Job-Shop-Scheduling/GIN_dir/rl_utils.py:94\u001b[0m, in \u001b[0;36mtrain_on_policy_agent_parallel_envs\u001b[0;34m(instances, agent, num_iterations, num_episodes_per_iter, return_lists, makespan_lists)\u001b[0m\n\u001b[1;32m     92\u001b[0m     makespan_lists[env\u001b[38;5;241m.\u001b[39mname]\u001b[38;5;241m.\u001b[39mappend(info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmakespan\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     93\u001b[0m     return_lists[env\u001b[38;5;241m.\u001b[39mname]\u001b[38;5;241m.\u001b[39mappend(episode_return)\n\u001b[0;32m---> 94\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransition_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/DRL-for-Job-Shop-Scheduling/GIN_dir/agent.py:161\u001b[0m, in \u001b[0;36mPPO.update\u001b[0;34m(self, transition_dict)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# print(self.performe_GIN_extract(states).size())                       # [36, 64]\u001b[39;00m\n\u001b[1;32m    160\u001b[0m advantage \u001b[38;5;241m=\u001b[39m rl_utils\u001b[38;5;241m.\u001b[39mcompute_advantage(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlmbda, td_delta\u001b[38;5;241m.\u001b[39mcpu())\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 161\u001b[0m old_log_probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m1\u001b[39m, actions))\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[1;32m    164\u001b[0m     log_probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor(states)\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m1\u001b[39m, actions))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/code/DRL-for-Job-Shop-Scheduling/GIN_dir/agent.py:64\u001b[0m, in \u001b[0;36mActor.forward\u001b[0;34m(self, states)\u001b[0m\n\u001b[1;32m     54\u001b[0m     batched_probs\u001b[38;5;241m.\u001b[39mappend(probs)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# print(pooled_h)\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# print(h_nodes)\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# print(h_candidates)\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# print(candidate_scores)\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# print(concateFea)\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# print(batched_probs)\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m batched_probs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatched_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batched_probs\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 6 but got size 10 for tensor number 36 in the list."
     ]
    }
   ],
   "source": [
    "return_lists = defaultdict(list)\n",
    "makespan_lists = defaultdict(list)\n",
    "rl_utils.train_on_policy_agent_parallel_envs(instances=instances, agent=agent, num_iterations=num_iterations, \\\n",
    "                                             num_episodes_per_iter=num_episodes_per_iter, return_lists=return_lists, makespan_lists=makespan_lists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "policy_dir = f\"saved_policies/train_multi_sizes_iter={num_iterations}_episode={num_episodes_per_iter}\"\n",
    "agent.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "dce9ce0b8994960befdaf1abc06919148bccb19973be1d090d69590bd56698c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
